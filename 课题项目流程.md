# NuCorpus 核应急领域大模型数据集构建系统 - 技术流程文档

> 版本：2026-01-11  
> 适用对象：系统开发者、核应急领域研究人员、数据集构建工程师

---

## 目录

1. [系统概述](#1-系统概述)
2. [技术架构](#2-技术架构)
3. [文档处理流程](#3-文档处理流程)
4. [问答对生成流程](#4-问答对生成流程)
5. [完整工作流程](#5-完整工作流程)
6. [数据库模型关系](#6-数据库模型关系)
7. [API接口体系](#7-api接口体系)
8. [可选功能模块](#8-可选功能模块)
9. [附录](#9-附录)

---

## 1. 系统概述

### 1.1 项目定位

NuCorpus 是一个专为核应急领域设计的大模型微调数据集构建系统。它提供了从文档上传、智能切分、问答生成到数据集导出的完整流水线，旨在解决以下核心问题：

| 问题编号 | 问题描述 | 解决方案 |
|---------|---------|---------|
| P1 | 多源文档难以规模化转为高质量训练样本 | 多格式解析 + 智能切分 |
| P2 | 核应急问答对的质量要求极高 | 核应急专用提示词 + 质量评估 |
| P3 | 缺少面向核应急的可复用数据生产流水线 | 一体化工具链 |
| P4 | 缺少可操作的评测与验收标准 | AI预评估 + 人工审核闭环 |

### 1.2 技术栈概览

```
┌─────────────────────────────────────────────────────────────┐
│                        前端层                                │
│  Next.js 14 (App Router) + React 18 + MUI v5 + i18next     │
├─────────────────────────────────────────────────────────────┤
│                        后端层                                │
│  Next.js API Routes + Node.js + Prisma ORM                 │
├─────────────────────────────────────────────────────────────┤
│                        数据层                                │
│  SQLite + local-db 文件存储                                  │
├─────────────────────────────────────────────────────────────┤
│                        AI 集成层                             │
│  OpenAI / Ollama / 智谱AI / OpenRouter / DeepSeek          │
├─────────────────────────────────────────────────────────────┤
│                        桌面应用层                            │
│  Electron (跨平台桌面应用)                                   │
└─────────────────────────────────────────────────────────────┘
```

---

## 2. 技术架构

### 2.1 目录结构

```
NuCorpus/
├── app/                          # Next.js 路由与 API
│   ├── api/                      # 后端 API 接口
│   │   ├── projects/[projectId]/ # 项目相关 API
│   │   │   ├── chunks/           # 文本块管理
│   │   │   ├── datasets/         # 数据集 CRUD & 导出
│   │   │   ├── questions/        # 问题管理
│   │   │   ├── split/            # 文本切分
│   │   │   ├── huggingface/      # HF 数据集上传
│   │   │   └── tasks/            # 后台任务
│   │   └── llm/                  # LLM 提供商 API
│   └── projects/[projectId]/     # 项目页面
│       ├── datasets/             # 数据集管理界面
│       ├── text-split/           # 文档处理界面
│       └── distill/              # 知识蒸馏界面
├── components/                   # UI 组件库
│   ├── datasets/                 # 数据集相关组件
│   ├── text-split/               # 文本切分组件
│   ├── export/                   # 导出功能组件
│   └── tasks/                    # 任务管理组件
├── lib/                          # 核心业务逻辑
│   ├── file/                     # 文件处理模块
│   │   ├── file-process/         # 格式解析器
│   │   │   ├── pdf/              # PDF 多策略解析
│   │   │   └── epub/             # EPUB 解析
│   │   ├── split-markdown/       # Markdown 切分器
│   │   └── text-splitter.js      # 统一切分入口
│   ├── llm/                      # LLM 集成
│   │   ├── core/                 # 统一调用接口
│   │   │   └── providers/        # 各提供商实现
│   │   └── prompts/              # 提示词模板
│   ├── services/                 # 业务服务层
│   │   ├── tasks/                # 后台任务处理
│   │   ├── questions/            # 问题生成服务
│   │   └── datasets/             # 数据集服务
│   ├── db/                       # 数据库访问层
│   └── graph/                    # 知识图谱模块
├── prisma/                       # 数据库 Schema
├── electron/                     # Electron 主进程
└── locales/                      # 国际化翻译
```

### 2.2 前端组件架构

```
组件层级结构:
├── Navbar/                       # 全局导航栏
├── text-split/                   # 文本切分模块
│   ├── FileUploader.js           # 文件上传组件
│   ├── PdfSettings.js            # PDF 解析设置
│   ├── ChunkList.js              # 文本块列表
│   └── ChunkViewDialog.js        # 块内容查看
├── questions/                    # 问题管理模块
│   ├── QuestionListView.js       # 问题列表视图
│   └── QuestionTreeView.js       # 问题树视图
├── datasets/                     # 数据集模块
│   ├── DatasetHeader.js          # 数据集头部
│   ├── DatasetRatingSection.js   # 评分区域
│   └── TagSelector.js            # 标签选择器
└── export/                       # 导出模块
    ├── LocalExportTab.js         # 本地导出
    ├── LlamaFactoryTab.js        # LlamaFactory 格式
    └── HuggingFaceTab.js         # HF 上传
```

### 2.3 LLM 提供商支持

系统通过统一的 `LLMClient` 类支持多种 LLM 提供商：

```javascript
// lib/llm/core/index.js
const clientMap = {
  ollama: OllamaClient,         // 本地离线部署
  openai: OpenAIClient,         // OpenAI API
  siliconflow: OpenAIClient,    // 硅基流动
  deepseek: OpenAIClient,       // DeepSeek
  zhipu: ZhiPuClient,           // 智谱 AI
  openrouter: OpenRouterClient, // OpenRouter
  alibailian: AlibailianClient  // 阿里百炼
};
```

**核心功能：**
- `chat()` - 标准对话生成
- `chatStream()` - 流式输出
- `getVisionResponse()` - 视觉模型调用
- `extractAnswerAndCOT()` - 思维链提取（支持 `<think>` 标签和 `reasoning_content`）

---

## 3. 文档处理流程

### 3.1 支持的文档格式

| 格式 | 扩展名 | 处理模块 | 说明 |
|-----|-------|---------|------|
| PDF | `.pdf` | `lib/file/file-process/pdf/` | 支持4种解析策略 |
| Word | `.docx` | mammoth 库 | 自动转换为 Markdown |
| Markdown | `.md` | 直接处理 | 原生支持 |
| EPUB | `.epub` | `lib/file/file-process/epub/` | 电子书格式 |
| 纯文本 | `.txt` | 直接读取 | 基础文本 |

### 3.2 PDF 解析策略详解

PDF 是核应急领域最常见的文档格式，系统提供四种解析策略以适应不同场景：

```
┌─────────────────────────────────────────────────────────────┐
│                    PDF 解析策略选择                          │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  ┌─────────────┐    ┌─────────────┐    ┌─────────────┐     │
│  │   default   │    │   vision    │    │   mineru    │     │
│  │   (默认)    │    │  (视觉AI)   │    │  (云端API)  │     │
│  └──────┬──────┘    └──────┬──────┘    └──────┬──────┘     │
│         │                  │                  │             │
│         ▼                  ▼                  ▼             │
│  pdf-parse 库        VLM 逐页解析       MinerU API         │
│  - 快速提取          - 高精度OCR        - 专业文档解析      │
│  - 适合文字PDF       - 支持扫描件       - 公式表格识别      │
│  - 成本：免费        - 成本：按页计费   - 成本：API计费     │
│                                                             │
│                    ┌─────────────┐                         │
│                    │mineru-local │                         │
│                    │ (本地部署)  │                         │
│                    └──────┬──────┘                         │
│                           │                                 │
│                           ▼                                 │
│                    本地 MinerU 服务                         │
│                    - 完全离线                               │
│                    - 适合敏感文档                           │
└─────────────────────────────────────────────────────────────┘
```

**策略实现入口** (`lib/file/file-process/pdf/index.js`):

```javascript
export async function processPdf(strategy = 'default', projectId, fileName, options = {}) {
  switch (strategy.toLowerCase()) {
    case 'default':
      return await defaultProcessing(projectId, fileName, options);
    case 'mineru':
      return await minerUProcessing(projectId, fileName, options);
    case 'vision':
      return await visionProcessing(projectId, fileName, options);
    case 'mineru-local':
      return await minerULocalProcessing(projectId, fileName, options);
  }
}
```

**Vision 策略详解** (`lib/file/file-process/pdf/vision.js`):
- 使用 `pdf2md-js` 库将 PDF 逐页转换为图片
- 调用视觉大模型（如 GPT-4V、Qwen-VL）进行 OCR
- 支持并发处理，通过 `visionConcurrencyLimit` 配置控制
- 包含进度回调，实时更新任务状态

### 3.3 文本切分策略

文档解析为 Markdown 后，需要进行智能切分以生成语义完整的文本块。

**切分入口** (`lib/file/text-splitter.js`):

```javascript
// 支持的切分类型
const splitTypes = {
  'text':      CharacterTextSplitter,    // 字符分块
  'token':     TokenTextSplitter,        // Token 分块
  'recursive': RecursiveCharacterTextSplitter, // 递归分块
  'code':      RecursiveCharacterTextSplitter.fromLanguage(), // 代码分块
  'custom':    customSeparator,          // 自定义分隔符
  'default':   markdownSplitter          // 标题层级切分（推荐）
};
```

**默认策略：标题层级切分** (`lib/file/split-markdown/`):

```
输入 Markdown 文档
        │
        ▼
┌─────────────────┐
│  提取文档大纲   │  parser.extractOutline()
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  按标题分割段落  │  parser.splitByHeadings()
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  处理段落合并   │  splitter.processSections()
│  (满足最小/最大) │  minSplitLength / maxSplitLength
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  生成摘要标签   │  summary.generateSummary()
└────────┬────────┘
         │
         ▼
输出 Chunks 数组
```

**配置参数** (`task-config.json`):

| 参数 | 默认值 | 说明 |
|-----|-------|------|
| `textSplitMinLength` | 1500 | 分块最小字符数 |
| `textSplitMaxLength` | 2000 | 分块最大字符数 |
| `chunkSize` | 1500 | Token/字符分块大小 |
| `chunkOverlap` | 200 | 分块重叠字符数 |
| `separator` | `\n\n` | 字符分块分隔符 |
| `customSeparator` | `---` | 自定义分隔符 |

---

## 4. 问答对生成流程

### 4.1 问题生成流程

文本块切分完成后，系统通过 LLM 为每个语义块生成问题。

**问题生成服务** (`lib/services/questions/index.js`):

```
文本块 (Chunk)
      │
      ▼
┌─────────────────────────┐
│   构建问题生成提示词     │
│   getQuestionPrompt()   │
│   - 核应急专用提示词     │
│   - 支持 GA 受众扩展     │
└───────────┬─────────────┘
            │
            ▼
┌─────────────────────────┐
│   调用 LLM 生成问题      │
│   llmClient.chat()      │
└───────────┬─────────────┘
            │
            ▼
┌─────────────────────────┐
│   解析 JSON 响应        │
│   extractJsonFromLLM()  │
└───────────┬─────────────┘
            │
            ▼
┌─────────────────────────┐
│   保存问题到数据库       │
│   saveQuestions()       │
└─────────────────────────┘
```

### 4.2 核应急专用提示词

系统针对核应急领域设计了专用提示词体系 (`lib/llm/prompts/`):

**通用问题生成提示词** (`question.js`):

```javascript
// 核心角色定义
Role: 核应急领域问题构建专家
Skills:
  1. 深度理解 - 识别核设施系统、事故演化逻辑、辐射防护措施
  2. 专业提问 - 聚焦"是什么/为什么/怎么办"
  3. 多维覆盖 - 覆盖法规标准、运行规程、SAMG及应急预案
  4. 格式规范 - 严格遵守 JSON 输出格式

Constraints:
  - 严禁幻觉：所有问题必须严格依据给定文本
  - 专业术语：使用标准核行业术语（LOCA、SBO、冷链中断等）
  - 避免元数据：不针对"本文作者"、"本章节"提问
```

**核应急专用模式** (`nuclear.js`):

| 模式 | 提示词 | 适用场景 |
|-----|-------|---------|
| EOP | `NUCLEAR_EOP_PROMPT` | 规程化问答，生成"征兆-判断-行动-依据"链式 CoT |
| JUDGEMENT | `NUCLEAR_JUDGEMENT_PROMPT` | 场景判别题，考察应急状态分级和 INES 分类 |

**EOP 模式示例输出**:
```json
{
  "question": "当稳压器水位低于 15% 且安全壳压力持续上升时，操纵员应采取什么行动？",
  "answer": "1. **现状分析**: 征兆表明可能发生 LOCA...\n2. **执行步骤**: 确认安注信号，启动...\n3. **依据**: EOP-01 第 3.2 节..."
}
```

### 4.3 答案生成流程

问题生成后，系统为每个问题生成对应答案，形成完整的问答对。

**答案生成服务** (`lib/services/datasets/index.js`):

```
问题 (Question) + 关联文本块 (Chunk)
                │
                ▼
┌─────────────────────────┐
│   构建答案生成提示词     │
│   getAnswerPrompt()     │
│   - 参考内容嵌入         │
│   - 问题嵌入            │
└───────────┬─────────────┘
            │
            ▼
┌─────────────────────────┐
│   调用 LLM 生成答案      │
│   getResponseWithCOT()  │
│   - 提取答案            │
│   - 提取思维链 (CoT)     │
└───────────┬─────────────┘
            │
            ▼
┌─────────────────────────┐
│   保存数据集到数据库     │
│   Datasets 表           │
│   - question            │
│   - answer              │
│   - cot (思维链)        │
│   - model (使用的模型)   │
└─────────────────────────┘
```

**答案提示词核心约束** (`answer.js`):

```
1. 绝对忠实：答案必须完全基于参考内容
2. 安全第一：严禁生成可能导致误操作的建议
3. 格式规范：答案应完整独立，适合 SFT
4. 纯净输出：直接输出答案，不包含"根据..."前缀
```

### 4.4 CoT 思维链处理

系统支持提取和保存模型的思维链（Chain of Thought）:

**提取逻辑** (`lib/llm/core/index.js`):

```javascript
extractAnswerAndCOT(llmRes) {
  let answer = llmRes.text || '';
  let cot = llmRes.reasoning || '';

  // 处理 <think> 标签格式
  if (answer.startsWith('<think>') || answer.startsWith('<thinking>')) {
    cot = extractThinkChain(answer);
    answer = extractAnswer(answer);
  }

  // 处理 reasoning_content 格式（DeepSeek 等模型）
  else if (llmRes.response?.body?.choices?.[0]?.message?.reasoning_content) {
    cot = llmRes.response.body.choices[0].message.reasoning_content;
    answer = llmRes.response.body.choices[0].message.content;
  }

  return { answer, cot };
}
```

### 4.5 质量评估机制

**AI 预评估** (`lib/llm/prompts/datasetEvaluation.js`):

```
评估维度                权重    评分标准
─────────────────────────────────────────
技术准确性              40%    参数、逻辑链、物理现象符合 FSAR
安全导向性              30%    体现"保守决策"和"纵深防御"
表述规范性              30%    使用标准术语
─────────────────────────────────────────

输出格式:
{
  "score": 4.5,
  "evaluation": "该样本技术准确性高，正确引用了 EOP-01 规程步骤..."
}
```

**人工审核闭环**:
- 前端提供数据集编辑界面
- 支持人工评分（StarRating 组件）
- 支持标签分类（TagSelector 组件）
- 支持备注和修改（NoteInput 组件）
- `confirmed` 字段标记审核状态

---

## 5. 完整工作流程

### 5.1 端到端数据集构建流程

```
┌─────────────────────────────────────────────────────────────────────────┐
│                         NuCorpus 完整工作流程                            │
└─────────────────────────────────────────────────────────────────────────┘

阶段 1: 项目初始化
┌─────────────┐
│  创建项目   │  POST /api/projects
│  - 项目名称  │  → Projects 表
│  - 项目描述  │
└──────┬──────┘
       │
       ▼
阶段 2: 文档上传与解析
┌─────────────┐     ┌─────────────┐     ┌─────────────┐
│  上传文档   │ ──► │  格式检测   │ ──► │  内容解析   │
│  POST files │     │  PDF/DOCX/  │     │  → Markdown │
└─────────────┘     │  MD/EPUB    │     └──────┬──────┘
                    └─────────────┘            │
                                               ▼
阶段 3: 智能切分                    ┌─────────────┐
                                    │  文本切分   │
                                    │  POST split │
                                    │  → Chunks   │
                                    └──────┬──────┘
                                           │
                                           ▼
阶段 4: 问题生成               ┌─────────────────────┐
                               │  批量问题生成        │
                               │  Task: question-gen  │
                               │  → Questions 表      │
                               └──────────┬──────────┘
                                          │
                                          ▼
阶段 5: 答案生成               ┌─────────────────────┐
                               │  批量答案生成        │
                               │  Task: answer-gen    │
                               │  → Datasets 表       │
                               └──────────┬──────────┘
                                          │
                                          ▼
阶段 6: 质量审核               ┌─────────────────────┐
                               │  AI 评估 + 人工审核  │
                               │  → score, confirmed  │
                               └──────────┬──────────┘
                                          │
                                          ▼
阶段 7: 数据导出               ┌─────────────────────┐
                               │  导出数据集          │
                               │  - Alpaca 格式       │
                               │  - ShareGPT 格式     │
                               │  - 自定义格式        │
                               └──────────┬──────────┘
                                          │
                                          ▼
阶段 8: 发布 (可选)            ┌─────────────────────┐
                               │  HuggingFace 上传    │
                               │  POST huggingface/   │
                               │      upload          │
                               └─────────────────────┘
```

### 5.2 后台任务处理机制

系统采用异步任务队列处理耗时操作。

**任务类型** (`lib/services/tasks/index.js`):

| 任务类型 | 处理函数 | 说明 |
|---------|---------|------|
| `file-processing` | `processFileProcessingTask` | 文件解析与转换 |
| `question-generation` | `processQuestionGenerationTask` | 批量问题生成 |
| `answer-generation` | `processAnswerGenerationTask` | 批量答案生成 |
| `data-cleaning` | `processDataCleaningTask` | 数据清洗 |
| `dataset-evaluation` | `processDatasetEvaluationTask` | AI 质量评估 |
| `multi-turn-generation` | `processMultiTurnGenerationTask` | 多轮对话生成 |
| `data-distillation` | `processDataDistillationTask` | 知识蒸馏 |
| `image-question-generation` | `processImageQuestionGenerationTask` | 图像问题生成 |
| `image-dataset-generation` | `processImageDatasetGenerationTask` | 图像数据集生成 |

**任务状态**:
```javascript
TASK.STATUS = {
  PROCESSING: 0,  // 处理中
  COMPLETED: 1,   // 已完成
  FAILED: 2,      // 失败
  ABORTED: 3      // 已中断
}
```

**任务处理流程**:

```javascript
// 创建任务
POST /api/projects/{projectId}/tasks
{
  taskType: 'question-generation',
  modelInfo: { ... },
  language: 'zh-CN'
}

// 任务调度器
processTask(taskId) {
  const task = await prisma.task.findUnique({ where: { id: taskId } });

  switch (task.taskType) {
    case 'question-generation':
      await processQuestionGenerationTask(task);
      break;
    // ...
  }
}

// 进度更新
updateTask(taskId, {
  completedCount: current,
  totalCount: total,
  detail: `已处理: ${current}/${total}`
});
```

---

## 6. 数据库模型关系

### 6.1 核心模型 ER 图

```
┌─────────────────────────────────────────────────────────────────────────┐
│                           数据库模型关系图                               │
└─────────────────────────────────────────────────────────────────────────┘

                              ┌─────────────┐
                              │  Projects   │
                              │─────────────│
                              │ id (PK)     │
                              │ name        │
                              │ description │
                              │ globalPrompt│
                              │ ...         │
                              └──────┬──────┘
                                     │
          ┌──────────────┬───────────┼───────────┬──────────────┐
          │              │           │           │              │
          ▼              ▼           ▼           ▼              ▼
┌─────────────┐  ┌─────────────┐  ┌──────┐  ┌─────────┐  ┌───────────┐
│ UploadFiles │  │   Chunks    │  │ Tags │  │  Task   │  │ModelConfig│
│─────────────│  │─────────────│  │──────│  │─────────│  │───────────│
│ id (PK)     │  │ id (PK)     │  │ id   │  │ id      │  │ id        │
│ projectId   │  │ projectId   │  │ label│  │ taskType│  │ providerId│
│ fileName    │  │ name        │  │parent│  │ status  │  │ modelId   │
│ fileExt     │  │ content     │  └──────┘  │ progress│  │ apiKey    │
│ path        │  │ summary     │            └─────────┘  └───────────┘
└──────┬──────┘  └──────┬──────┘
       │                │
       │                ▼
       │         ┌─────────────┐
       │         │  Questions  │
       │         │─────────────│
       │         │ id (PK)     │
       │         │ projectId   │
       │         │ chunkId (FK)│
       │         │ question    │
       │         │ label       │
       │         │ answered    │
       │         │ imageId     │
       │         └──────┬──────┘
       │                │
       ▼                ▼
┌─────────────┐  ┌─────────────┐
│   GaPairs   │  │  Datasets   │
│─────────────│  │─────────────│
│ id (PK)     │  │ id (PK)     │
│ fileId (FK) │  │ projectId   │
│ genreTitle  │  │ questionId  │
│ audienceDesc│  │ question    │
│ pairNumber  │  │ answer      │
└─────────────┘  │ cot         │
                 │ model       │
                 │ score       │
                 │ confirmed   │
                 └─────────────┘
```

### 6.2 核心模型字段说明

**Projects (项目表)**:
```prisma
model Projects {
  id                   String    @id @default(nanoid(12))
  name                 String    // 项目名称
  description          String    // 项目描述
  globalPrompt         String    // 全局系统提示词
  questionPrompt       String    // 自定义问题提示词
  answerPrompt         String    // 自定义答案提示词
  defaultModelConfigId String?   // 默认模型配置
  // 关联
  Chunks               Chunks[]
  Questions            Questions[]
  Datasets             Datasets[]
  Task                 Task[]
}
```

**Chunks (文本块表)**:
```prisma
model Chunks {
  id        String      @id
  name      String      // 块标识名
  projectId String      // 所属项目
  fileId    String      // 来源文件
  fileName  String      // 文件名
  content   String      // 块内容
  summary   String      // 摘要
  size      Int         // 字符数
  Questions Questions[] // 关联问题
}
```

**Questions (问题表)**:
```prisma
model Questions {
  id         String   @id
  projectId  String   // 所属项目
  chunkId    String   // 关联文本块
  question   String   // 问题内容
  label      String   // 问题标签
  answered   Boolean  // 是否已生成答案
  imageId    String?  // 关联图片(可选)
  templateId String?  // 问题模板(可选)
}
```

**Datasets (数据集表)**:
```prisma
model Datasets {
  id            String   @id
  projectId     String   // 所属项目
  questionId    String   // 关联问题
  question      String   // 问题内容
  answer        String   // 答案内容
  cot           String   // 思维链
  model         String   // 生成模型
  chunkName     String   // 来源块名
  chunkContent  String   // 来源块内容
  score         Float    // 评分
  confirmed     Boolean  // 审核确认
  aiEvaluation  String   // AI评估结论
  tags          String   // 标签(JSON)
}
```

---

## 7. API 接口体系

### 7.1 项目管理 API

| 方法 | 路径 | 说明 |
|-----|------|------|
| GET | `/api/projects` | 获取项目列表 |
| POST | `/api/projects` | 创建新项目 |
| GET | `/api/projects/{projectId}` | 获取项目详情 |
| PUT | `/api/projects/{projectId}` | 更新项目信息 |
| DELETE | `/api/projects/{projectId}` | 删除项目 |

### 7.2 文件处理 API

| 方法 | 路径 | 说明 |
|-----|------|------|
| POST | `/api/projects/{projectId}/files` | 上传文件 |
| GET | `/api/projects/{projectId}/files` | 获取文件列表 |
| DELETE | `/api/projects/{projectId}/files/{fileId}` | 删除文件 |
| POST | `/api/projects/{projectId}/split` | 执行文本切分 |

### 7.3 文本块 API

| 方法 | 路径 | 说明 |
|-----|------|------|
| GET | `/api/projects/{projectId}/chunks` | 获取文本块列表 |
| GET | `/api/projects/{projectId}/chunks/{chunkId}` | 获取块详情 |
| PUT | `/api/projects/{projectId}/chunks/{chunkId}` | 更新块内容 |
| DELETE | `/api/projects/{projectId}/chunks/{chunkId}` | 删除块 |
| POST | `/api/projects/{projectId}/chunks/batch` | 批量操作 |

### 7.4 问题管理 API

| 方法 | 路径 | 说明 |
|-----|------|------|
| GET | `/api/projects/{projectId}/questions` | 获取问题列表 |
| POST | `/api/projects/{projectId}/questions` | 创建问题 |
| PUT | `/api/projects/{projectId}/questions/{questionId}` | 更新问题 |
| DELETE | `/api/projects/{projectId}/questions/{questionId}` | 删除问题 |
| POST | `/api/projects/{projectId}/questions/generate` | 生成问题 |

### 7.5 数据集 API

| 方法 | 路径 | 说明 |
|-----|------|------|
| GET | `/api/projects/{projectId}/datasets` | 获取数据集列表 |
| POST | `/api/projects/{projectId}/datasets` | 创建数据集条目 |
| PUT | `/api/projects/{projectId}/datasets/{datasetId}` | 更新数据集 |
| DELETE | `/api/projects/{projectId}/datasets/{datasetId}` | 删除数据集 |
| POST | `/api/projects/{projectId}/datasets/generate` | 生成答案 |
| GET | `/api/projects/{projectId}/datasets/export` | 导出数据集 |

### 7.6 任务管理 API

| 方法 | 路径 | 说明 |
|-----|------|------|
| GET | `/api/projects/{projectId}/tasks` | 获取任务列表 |
| POST | `/api/projects/{projectId}/tasks` | 创建任务 |
| GET | `/api/projects/{projectId}/tasks/{taskId}` | 获取任务状态 |
| DELETE | `/api/projects/{projectId}/tasks/{taskId}` | 取消任务 |

### 7.7 LLM 相关 API

| 方法 | 路径 | 说明 |
|-----|------|------|
| GET | `/api/llm/models` | 获取可用模型列表 |
| POST | `/api/llm/chat` | 单次对话 |
| POST | `/api/llm/chat/stream` | 流式对话 |
| GET | `/api/llm/providers` | 获取提供商列表 |

### 7.8 HuggingFace 发布 API

| 方法 | 路径 | 说明 |
|-----|------|------|
| POST | `/api/projects/{projectId}/huggingface/upload` | 上传到 HF |
| GET | `/api/projects/{projectId}/huggingface/check` | 检查仓库状态 |

**上传请求示例**:
```javascript
POST /api/projects/{projectId}/huggingface/upload
{
  "token": "hf_xxx...",           // HuggingFace API Token
  "repoName": "my-nuclear-dataset", // 仓库名称
  "isPrivate": false,             // 是否私有
  "format": "jsonl",              // 导出格式: json/jsonl/csv
  "datasetFormat": "alpaca"       // 数据格式: alpaca/sharegpt
}
```

---

## 8. 可选功能模块

### 8.1 知识图谱抽取 (PoC)

系统提供可选的知识图谱抽取功能，用于构建核应急领域知识网络。

**架构**:
```
文本块 (Chunk)
      │
      ▼
┌─────────────────────────┐
│  三元组抽取提示词        │
│  lib/llm/prompts/graph.js│
└───────────┬─────────────┘
            │
            ▼
┌─────────────────────────┐
│  LLM 抽取三元组          │
│  (实体, 关系, 实体)      │
└───────────┬─────────────┘
            │
            ▼
┌─────────────────────────┐
│  Neo4j 入库              │
│  lib/graph/neo4j.js     │
└─────────────────────────┘
```

**启用步骤**:
1. 安装依赖: `pnpm add neo4j-driver`
2. 配置环境变量:
   ```env
   NEO4J_URI=bolt://localhost:7687
   NEO4J_USER=neo4j
   NEO4J_PASSWORD=your_password
   ```
3. 在切分/生成流程中调用 `GraphService.processChunk(text, sourceId)`

**三元组抽取提示词** (`lib/llm/prompts/graph.js`):
```javascript
// 核应急领域实体类型
EntityTypes: [
  '核设施', '系统', '设备', '事故类型', '应急状态',
  '规程', '参数', '人员角色', '组织机构', '法规标准'
]

// 关系类型
RelationTypes: [
  '包含', '触发', '导致', '依据', '执行', '监测', '控制'
]
```

### 8.2 多轮对话生成

系统支持将单轮问答扩展为多轮对话，适用于对话式 AI 训练。

**生成流程**:
```
单轮 QA 对
    │
    ▼
┌─────────────────────────┐
│  多轮对话扩展提示词      │
│  multiTurnConversation.js│
└───────────┬─────────────┘
            │
            ▼
┌─────────────────────────┐
│  LLM 生成追问与回答      │
│  - 追问1 → 回答1        │
│  - 追问2 → 回答2        │
│  - ...                  │
└───────────┬─────────────┘
            │
            ▼
┌─────────────────────────┐
│  保存为 ShareGPT 格式    │
│  conversations 数组      │
└─────────────────────────┘
```

### 8.3 图像数据集生成

系统支持处理图像文档，生成图像问答数据集。

**支持场景**:
- 核设施流程图理解
- 仪表盘读数识别
- 设备状态判断
- 图表数据提取

**处理流程**:
```
图像文件
    │
    ▼
┌─────────────────────────┐
│  视觉模型分析            │
│  getVisionResponse()    │
└───────────┬─────────────┘
            │
            ▼
┌─────────────────────────┐
│  生成图像描述            │
│  → Images 表            │
└───────────┬─────────────┘
            │
            ▼
┌─────────────────────────┐
│  生成图像问题            │
│  → Questions (imageId)  │
└───────────┬─────────────┘
            │
            ▼
┌─────────────────────────┐
│  生成图像答案            │
│  → ImageDatasets 表     │
└─────────────────────────┘
```

### 8.4 GA 受众扩展 (Genre-Audience)

系统支持为同一文本块生成面向不同受众的问答对。

**配置** (`GaPairs` 模型):
```javascript
{
  genreTitle: "技术培训",      // 体裁
  audienceDescription: "新入职操纵员", // 受众描述
  pairNumber: 3               // 生成问答对数量
}
```

**应用场景**:
- 同一技术内容，面向不同层级人员
- 同一事故场景，面向不同岗位角色
- 同一规程条款，面向培训/考核/参考

---

## 9. 附录

### 9.1 数据导出格式

**Alpaca 格式**:
```json
{
  "instruction": "当稳压器水位低于15%时应采取什么措施？",
  "input": "",
  "output": "1. 确认安注信号已触发...",
  "system": "你是核电站应急响应专家..."
}
```

**ShareGPT 格式**:
```json
{
  "conversations": [
    {"from": "human", "value": "当稳压器水位低于15%时应采取什么措施？"},
    {"from": "gpt", "value": "1. 确认安注信号已触发..."}
  ],
  "system": "你是核电站应急响应专家..."
}
```

**Multilingual-Thinking 格式** (含思维链):
```json
{
  "instruction": "当稳压器水位低于15%时应采取什么措施？",
  "input": "",
  "output": "<think>首先分析征兆...</think>\n\n1. 确认安注信号已触发...",
  "system": "你是核电站应急响应专家..."
}
```

### 9.2 常用命令速查

```bash
# 开发环境
pnpm install          # 安装依赖
pnpm db:push          # 初始化数据库
pnpm dev              # 启动开发服务器 (端口 1717)

# 生产环境
pnpm build            # 构建生产版本
pnpm start            # 启动生产服务器

# 数据库工具
pnpm db:studio        # 打开 Prisma Studio

# Electron 桌面应用
pnpm electron-dev     # Electron 开发模式
pnpm electron-build-mac   # 构建 macOS 应用
pnpm electron-build-win   # 构建 Windows 应用
pnpm electron-build-linux # 构建 Linux 应用

# Docker
docker-compose up -d  # 启动 Docker 容器
```

### 9.3 环境变量配置

```env
# 数据库
DATABASE_URL=file:./db.sqlite
LOCAL_DB_PATH=./local-db

# LLM API Keys (按需配置)
OPENAI_API_KEY=sk-xxx
DEEPSEEK_API_KEY=sk-xxx
ZHIPU_API_KEY=xxx

# 知识图谱 (可选)
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=xxx
```

### 9.4 核应急领域术语表

| 缩写 | 全称 | 说明 |
|-----|------|------|
| EOP | Emergency Operating Procedure | 应急运行规程 |
| SAMG | Severe Accident Management Guidelines | 严重事故管理导则 |
| LOCA | Loss of Coolant Accident | 失水事故 |
| SBO | Station Blackout | 全厂断电 |
| INES | International Nuclear Event Scale | 国际核事件分级 |
| FSAR | Final Safety Analysis Report | 最终安全分析报告 |
| CoT | Chain of Thought | 思维链 |
| SFT | Supervised Fine-Tuning | 监督微调 |

### 9.5 质量标准参考

**数据集质量评估维度**:

| 维度 | 权重 | 评分标准 |
|-----|------|---------|
| 技术准确性 | 40% | 参数、逻辑链、物理现象符合 FSAR |
| 安全导向性 | 30% | 体现"保守决策"和"纵深防御"原则 |
| 表述规范性 | 30% | 使用标准核行业术语 |

**推荐评分阈值**:
- 5.0 分：可直接用于训练
- 4.0-4.9 分：建议人工复核后使用
- 3.0-3.9 分：需要修改后使用
- < 3.0 分：建议重新生成

### 9.6 扩展开发指南

**添加新的 LLM 提供商**:
1. 在 `lib/llm/core/providers/` 创建提供商文件
2. 实现 `chat()`, `chatStream()` 等标准接口
3. 在 `lib/llm/core/index.js` 中注册
4. 更新前端设置界面

**添加新的文件格式**:
1. 在 `lib/file/file-process/` 添加处理器
2. 更新 `lib/file/index.js` 中的格式检测
3. 更新前端上传组件的文件类型限制

**添加新的导出格式**:
1. 在 `components/export/` 添加导出逻辑
2. 更新 `ExportDatasetDialog.js` 中的格式选项
3. 在后端 API 中添加格式转换函数

---

## 文档版本历史

| 版本 | 日期 | 作者 | 说明 |
|-----|------|------|------|
| 1.0 | 2026-01-11 | NuCorpus Team | 初始版本 |

---

*本文档由 NuCorpus 项目组维护，如有问题请联系项目负责人。*


